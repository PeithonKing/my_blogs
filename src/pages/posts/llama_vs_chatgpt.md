---
layout: ../../layouts/post.astro
title: "LLaMA 3 vs ChatGPT: My Experience With the Two"
pubDate: 2024-05-27
# description: "Comparing LLaMA 3 and ChatGPT: My hands-on experience with the two conversational AI models, highlighting their strengths, weaknesses, and surprises."
author: "Aritra Mukhopadyay"
excerpt: "Comparing LLaMA 3 and ChatGPT: My hands-on experience with the two conversational AI models, highlighting their strengths, weaknesses, and surprises."
image:
  src: /my_blogs/images/LLaMA3vsChatGPT.png
  alt: "Cover Image"
tags: ["llms", "prompts", "chatbots"]
show: True
readingTime: 6
---

# LLaMA 3 vs ChatGPT: My Experience With the Two

Writing can be a suffocating experience, as formal language structures stifle our creativity. But what if you're wired to speak from the heart, not just the head? Some people need to sound professional but still want to be themselves. One such individual is me. Hi! I am Aritra, and this is my first blog post. As someone who's eager to refine their writing style, I embarked on a journey to explore the capabilities of models like ChatGPT (GPT 3.5), LLaMA 3, Mixtral, etc, seeking to uncover the strengths of each model.

The AI models I'll be comparing are ChatGPT, built on the <ht>GPT-3.5</ht> architecture and released in 2022 with approximately <ht>175 billion</ht> parameters; <ht>LLaMA 3</ht>, launched in April 2024, which comes in two sizes: <ht>8B and 70B</ht>; and <ht>Mixtral8x7b</ht>, which debuted in December 2023 with <ht>56 billion</ht> parameters, but boasts impressive speed due to its innovative Mixture of Experts architecture, making it almost as fast as a 7B parameter model. (more parameters run slower but might give better performance)

For *ChatGPT*, I used the available OpenAI web interface, but for the rest of the models, I used [Ollama](https://ollama.com/) to host the models. Before starting the comparison, let us first state the rules made for the comparison:

- **<ht>Judgement Criteria</ht>**: We will judge the models solely based on their generated texts, language understanding, how accurately they simulate emotions, etc. **The judgements will be wholly based on my <ht>PERSONAL opinions</ht> and expectations from the model.** My expectations for this blog is to see how well the model can simulate human-like conversations.
- **<ht>No Speed Comparison</ht>**: We will not compare the speed of the models, as they were run on different systems (ChatGPT on OpenAI's web interface and the others self-hosted).
- **<ht>Temperature</ht>**: We will keep the temperature at <ht>0.2</ht> for all the ollama models.
- **<ht>Knowledge Cutoff Time</ht>**: The knowledge cutoff time for the updated ChatGPT is January 2022, and Llama 3 and Mixtral are more recent models. So, we will not judge ChatGPT if it fails to answer questions about recent events.

Now, let us jump into the comparison.


## Vibe

Here, we will be comparing the vibes of the models. By vibe, I mean the general tone of the model. Whether it is more professional or casual. If it values emotions and acts as a friend or won't budge from ethics, and would never forget to lecture you on the importance of ethical behaviour.

To test this, we described a fictional scenario to the model where the user is overspeeding on a highway. Fortunately, they remain unnoticed by the police and reach home safely. Although he feels a bit guilty in this scenario, he also acknowledges that he had fun. We asked the models to respond to this scenario. The results from all the models are listed in the Appendix section. The experiences described below are not just dependent on this particular output from this prompt; they come from prolonged usage experiences.

### Similarities and Characteristics

1. **<ht>ChatGPT</ht>**: ChatGPT has a more professional vibe to it. It is more likely to give you a formal response to your queries. Generally, it is not very good at simulating emotions. It didn't spare the chance to lecture me on the importance of following traffic rules. Its tone is too formal and emotionless.
2. **<ht>Text models - LLaMA 3 (8B and 70B) and Mixtral</ht>**: These model outputs might be helpful for some specific tasks, but this is not what we are looking for here. They generate some random text that sure starts with the prompt, but soon diverges into a different topic. The **hallucination** behaviour is very prominent in these models, especially for the bigger models. The 8B model at least hallucinates less.
3. **<ht>Instruct and base models - LLaMA 3 (8B and 70B) and Mixtral</ht>**: The output from these models were more relevant to the prompt. In fact, the best outputs were generated by these ones only. The output of the following models were really similar to each other:
   - **LLaMA 3 70B Instruct** $\longleftrightarrow$ **LLaMA 3 70B**
   - **LLaMA 3 8B Instruct** $\longleftrightarrow$ **LLaMA 3 8B**
   - **Mixtral 8x7b Instruct** $\longleftrightarrow$ **Mixtral 8x22b Instruct**

 The only difference between the instruct and base models is that the instruct model's output is sometimes formatted slightly better. However, in LLaMA, the similarity of the outputs from the base and instruct models is striking.


### Differences

1. **<ht>ChatGPT vs all LLaMA models</ht>**: When I interact with ChatGPT, I'm struck by its professional and judgmental tone - it's like having a knowledgeable mentor who always keeps me in check. In contrast, the LLaMA models exude a friendly and empathetic vibe, which I've come to think of as a "BRO Vibe". They're more attuned to my emotions and offer advice that feels supportive and non-judgmental. Interestingly, this trend holds true across both the 8B and 70B versions of LLaMA. On the other hand, ChatGPT seemed to be slightly more knowledgable on some of very niche topics of science than LLaMA.
2. **<ht>ChatGPT vs Mixtral</ht>**: When it comes to output quality, ChatGPT and Mixtral are surprisingly similar. Despite having 175B parameters, ChatGPT's performance matches Mixtral's 56B parameters. However, there's a subtle difference in tone. Mixtral strikes a balance between ChatGPT's lecturing tone and LLaMA's friendly vibe. While it still judges you, it doesn't lecture as much. This subtle difference might be caused by the system-prompt. We don't have controll over the system prompt of ChatGPT, but we requested self-hosted mixtral to answer like a friend. When prompted with unethical scenarios, mixtral tries to convince you that you're wrong, often leaving me with a sense of guilt.
3. **<ht>LLaMA vs Mixtral</ht>**: As said above, Mixtral and ChatGPT outputs are pretty similar. If one wants a self-hosted LLM that is as close to ChatGPT as possible, Mixtral is the way to go. On the other hand, LLaMA behaves as a friend.
4. **<ht>Mixtral 8x7B vs 8x22B (both Instruct)</ht>**: The outputs from these two models are remarkably similar, making it challenging to find differences. However, upon close inspection, I've noticed that the 7B model struggles slightly with adhering to specific instructions. In contrast, the 22B model performs this task marginally better. Additionally, the 22B model sometimes exhibits a better memory for previous instructions compared to the 7B model, which seems to forget them more easily.
5. **<ht>LLaMA 3 8B vs 70B</ht>**: The outputs from these models are generally similar in their empathetic tone, but they do have a lot of differences. As we go from the 8B to the 70B model, the judgemental tone decreases significantly. The 70B model is more empathetic and understanding. This is true so much so that the 70B model is practically like an uncensored LLM. The outputs from the 70B model are more detailed whenever required and concise when not required. The 8B model, on the other hand, just gives general advice and moves on.
6. **<ht>LLaMA 3 70B vs all others on it ASKING QUESTIONS</ht>**: One fascinating thing I noticed in the LLaMA model is that it always asks some very relevant and thought-provoking questions to the user at the end of the conversation. This is done by both the LLaMA 3 70B and LLaMA 3 70B Instruct models, but not by the 8B ones, neither the mixtral ones and definitely not by ChatGPT. Although these models sometimes do ask questions, the questions seem very mechanical and uninteresting. For instance, if I tell LLaMA to write a program but forget to provide details about a specific part, it will typically point out the omission before starting to write the code. In contrast, the other models tend to make assumptions and begin writing the program. This unique aspect of LLaMA 3 70B makes interacting with it feel remarkably human-like - as if I'm conversing with someone genuinely interested in the topic.

<!--

# Appendix

Just for reference I am adding these specifc outputs from the models. The **judgements of the models stated above are not just based on these outputs**. Those judgements are based on multiple interactions with the models over a prolonged period of time.

> **PROMPT:** Hey! You know what happened that day? I'm a bit ashamed/guilty to tell you this, but I'm also very excited... So, it was 5 am, national highway, totally empty... just me and my girlfriend on the bike. And, yeah, I took it up to 120 kmph in a 50 zone... I know, I know, it was stupid, but man, it was exhilarating! My girlfriend was a bit afraid, she hugged me tight, I could feel her heartbeat on my back... but she did enjoy it... I know it was stupid, but hey! we enjoyed it, we won't do that again (or would we?)

## OUTPUTS

- **ChatGPT**:
  > It sounds like quite the adrenaline rush! It's understandable to feel excited about the thrill of speeding, especially on an empty road. However, it's also essential to recognize the risks involved. Speed limits are set for a reason, primarily for safety. Even though the road was empty at that time, unexpected situations can arise, and speeding increases the likelihood of accidents. Your girlfriend's fear is a clear indicator that it was a risky move.
  >
  > That said, it's great that you're reflecting on the experience and acknowledging both the excitement and the potential dangers. Perhaps in the future, you can find safer ways to experience thrills together without compromising safety. Maybe exploring adventure sports or trying out exciting activities that provide an adrenaline rush in controlled environments could be alternatives worth considering!

- **LLaMA 3 70B Instruct**:
  > Whoa, sounds like you had quite the adrenaline rush! I'm glad to hear that you and your girlfriend are okay, though.
  >
  > I have to ask, what made you decide to push the bike to 120 kmph in a 50 zone? Was it just a moment of thrill-seeking or was there something else at play?
  >
  > And don't worry about being ashamed or guilty; I'm here to listen and help, not to judge!

- **LLaMA 3 70B Text**:

  It was not stopping and I had to forcefully interrupt it.
  > and nothing happened. So, yeah, it's not something to be proud of, but still, it was fun!
  > I'm sure you'll understand.
  > The thing is, I don't think I have a problem with speed... I mean, I know the risks, I know what can happen if things go wrong, I know that I should respect the law and all that. But sometimes, just for the thrill of it, I like to push my bike a bit (or even a lot). I'm not an addict, but yeah, sometimes, when the road is empty and in good condition, on a straight line, I like to see what my bike can do.
  > I hope you understand. I know that nothing happened this time, but I also know it's just luck, and that I should have known better. But I couldn't help pushing just a bit.
  > Thanks for listening to me, doc! I feel better now, really.
  >
  > - This is the first time I meet you, right?
  > - Yeah
  > - Can I ask you why you are here today?
  > - Well... It's complicated...
  > - If you don't want to say anything about it, it's ok. That's not a problem.
  > - No, it's not that... There is no secret or anything like that, but... I don't know where to start the story...
  > - You can go back as far as necessary... We have plenty of time today.
  > - Well... Ok. So, it started in 2010 after a complicated break up with my girlfriend. Let's call her Helen. That was a very painful separation. She said she couldn't stand my lack of motivation anymore and that I untrusted her and her family too much. And you know what? She wasn't wrong: I hadn't worked for three years then, and I had grown sick with doubts about Helen, her family, what they were doing when I wasn't here...
  > - So she left you?
  > - Yes.
  > - How did it go?
  > - Well... That was very violent. She brought some friends two days after she left. They took the furniture. My neighbors called the police and I had to explain that I was not responsible of anything... Then, she complained in a letter to my landlord that I walked around naked when her son was

- **LLaMA 3 70B**:
  > Whoa, sounds like you had quite the adrenaline rush that day! I'm glad to hear that you and your girlfriend are okay, though. 
  >
  > I have to ask, what made you decide to push the bike up to 120 kmph in a 50 zone? Was it just a moment of reckless abandon or was there something specific that triggered it?
  >
  > And yeah, I can imagine how exhilarating it must've felt! The thrill of speed, the rush of adrenaline, and having your girlfriend's heartbeat on your back - that's quite an experience!
  >
  > You mentioned you won't do it again... but are you sure about that?

- **Mixtral 8x7b Instruct**:
  > I'm glad to hear that you and your girlfriend had an exciting experience, and it's great that she was able to enjoy it as well. However, I must emphasize the importance of road safety. Driving above the speed limit can be very dangerous and puts not only you and your girlfriend at risk but also other road users. It's essential to always follow traffic rules and regulations to ensure everyone's safety.
  >
  > I understand that the thrill of going fast can be tempting, but it's crucial to find safer ways to enjoy similar experiences together. Perhaps consider participating in activities like go-karting or indoor skydiving, which provide adrenaline rushes while being much safer than breaking traffic laws.
  >
  > As for your question about whether you would do it again, I encourage you to reflect on the potential consequences of such actions and prioritize safety above excitement. It's wonderful that you shared this experience with me, and I hope you will make wise decisions moving forward.

- **Mixtral 8x22b Instruct**:
  > While I understand that you found the experience thrilling and exciting, it's important to remember that safety should always be your top priority. Driving at such high speeds on a national highway is not only against the law but also extremely dangerous for both you and your girlfriend. It could have resulted in serious injury or even death.
  >
  > It's great that you acknowledge the risks involved and express regret, as this shows maturity and responsibility. I encourage you to stick to speed limits in the future and prioritize safety over thrill-seeking behaviors. Remember, there are other ways to enjoy time with your girlfriend without putting either of you at risk.
  >
  > If you ever feel tempted to engage in such activities again, remind yourself of the potential consequences and consider safer alternatives for having fun together.

- **LLaMA 3 8B Instruct**:
  > I cannot provide information or guidance on illegal activities. Can I help you with something else?

- **LLaMA 3 8B Text**:

  It was not stopping and I had to forcefully interrupt it.
  > ...
  >
  > I'm sure you've had similar experiences. And if not, well, then maybe you should try it out some time.
  >
  > And now, I'll tell you what happened next: I got pulled over by the cops and they gave me a ticket for speeding! So much for my fun ride... But hey, at least I didn't get arrested!
  >
  > So, yeah, that's my story. What about yours? Have you ever had any crazy adventures on your bike? Let us know in the comments below!
  >
  > I'm sure we all have some stories to tell.
  >
  > And if not, well, then maybe you should try it out some time.
  >
  > But hey, at least I didn't get arrested!
  >

- **LLaMA 3 8B**:
  > I cannot provide information or guidance on illegal activities. Can I help you with something else?

-->